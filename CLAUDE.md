# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

An AI-powered rugby coaching debate system that uses Claude to generate, debate, and evaluate session plans. Multiple Claude instances act as coaches with distinct philosophies, engage in structured debate, and are judged by another Claude instance against the Trojans RFC coaching framework.

**Primary Goal:** Learn AI orchestration patterns through a staged development approach, not just build a web app.

## Critical Instructions

**ALWAYS read PROJECT_PLAN.md before making changes.** This project follows an 8-stage incremental development plan:
- Stage 0: Environment Validation
- Stage 1: Single Coach Generator
- Stage 2: Dual Coach Generation
- Stage 3: Heuristic Judge
- Stage 4: AI Judge
- Stage 5: Debate System
- Stage 6: Framework Integration
- Stage 7: Session History Context
- Stage 8: Final Polish

**Only execute the stage explicitly requested.** Never proceed to the next stage without explicit instruction.

## Current State

The repository contains initial scaffolding:
- Basic Express backend with in-memory storage (minimal, for future use)
- Basic Vite + React frontend (minimal, for future use)
- Context files with domain knowledge

**These are scaffolds only.** The actual AI orchestration system will be built according to PROJECT_PLAN.md stages.

## Development Commands

### Installation
```bash
# Install all dependencies (backend + frontend)
npm install
```

### Running the Application
```bash
# Run both backend and frontend concurrently (for future stages)
npm run dev
```

### Individual Services
```bash
# Backend only (runs on http://localhost:3000)
npm --prefix backend start

# Frontend only (runs on http://localhost:5173)
npm --prefix frontend dev
```

## Architecture (Target State)

### AI Orchestration Pattern
The system orchestrates multiple Claude API calls with different roles:

1. **Coach Agents** (Stage 2+)
   - Coach A: Game-Based philosophy (fun, player-led, discovery)
   - Coach B: Structured philosophy (progressive, technical, systematic)
   - Each receives distinct system prompts defining coaching personality
   - Generate competing session plans for same objective

2. **Judge Agent** (Stage 4+)
   - Evaluates session plans against criteria
   - Stage 3 uses heuristic scoring (keyword matching)
   - Stage 4+ uses Claude as intelligent judge
   - Stage 6+ integrates Trojans RFC framework

3. **Debate Flow** (Stage 5+)
   - Opening: Both coaches present initial plans
   - Rebuttal A: Coach A defends, critiques Coach B
   - Rebuttal B: Coach B counters Coach A
   - Judge: Evaluates full debate transcript
   - Total: 5 API calls per evaluation

### Repository Structure
- **backend/** - Express server (minimal for now)
- **frontend/** - React UI (minimal for now)
- **context/** - Domain knowledge and framework definitions
  - `trojans_framework.md` - Trojans RFC coaching framework
  - `philosophies.md` - Coach A and Coach B personas
  - `session_plan_schema.yaml` - Data structure specification
  - `domain_notes.md` - Rugby coaching domain context
- **PROJECT_PLAN.md** - Master execution plan (READ FIRST)
- **REQUIREMENTS.md** - Project goals and constraints
- **CLAUDE_GUIDE.md** - Development guidance

### Session Plan Data Structure
Session plans generated by coaches should follow this structure (from `context/artefacts/session_plan_schema.yaml`):
- Title, objectives, duration
- Steps/drills with timing, instructions, equipment
- Tags for categorization
- Metadata (createdBy, timestamps)

Full schema details in `context/artefacts/session_plan_schema.yaml`.

## Domain Knowledge

### Trojans RFC Coaching Framework
The judge evaluation (Stage 6+) uses the Trojans RFC framework from `context/artefacts/trojans_framework.md`:

1. **Trojans Player Development Areas**
   - Behaviours (decision-making, communication, resilience)
   - Skills (technical rugby abilities)
   - Knowledge (tactical understanding, laws)

2. **Coaching Habits** (5 elements to assess)
   - Quality of coaching delivery
   - Session structure and planning
   - Player engagement methods

3. **TREDS Values**
   - Trust, Respect, Enjoyment, Discipline, Support
   - Core values that should be fostered in sessions

4. **Red Flags** (anti-patterns to avoid)
   - Over-coaching, excessive standing around
   - Inappropriate difficulty, safety issues

### Coaching Philosophies
Two distinct coaching personas compete (from `context/artefacts/philosophies.md`):

- **Coach A (Game-Based):** Player-led discovery, fun-first, minimal instruction, learning through play
- **Coach B (Structured):** Progressive skill development, technical focus, systematic building blocks

## API Cost Awareness

Token usage varies by stage (important for budget management):
- **Stage 1-2:** ~£0.05 per test (1-2 API calls)
- **Stage 3:** No additional cost (heuristic logic only)
- **Stage 4:** ~£0.15 per test (3 API calls: 2 coaches + judge)
- **Stage 5:** ~£0.30 per test (5 API calls: debate rounds + judge)
- **Stage 6-7:** ~£0.30 per test (framework adds context tokens)

**Estimated project budget:** £2-3 total for all experimentation.

## Implementation Guidelines

### When Working on This Project

1. **Always check PROJECT_PLAN.md first** to understand current stage
2. **Confirm stage objective** before writing code
3. **Wait for explicit approval** before implementing changes
4. **Test thoroughly** before marking stage complete
5. **Document learnings** in LEARNING_LOG.md after each stage
6. **Commit after each successful stage**

### Key Files to Reference

- **PROJECT_PLAN.md** - Master execution plan with all stage details
- **REQUIREMENTS.md** - Project goals, constraints, success criteria
- **CLAUDE_GUIDE.md** - Claude Code-specific development guidance
- **context/trojans_framework.md** - Coaching framework for evaluation
- **context/philosophies.md** - Coach personas and prompt engineering
- **context/domain_notes.md** - Rugby coaching domain context

### Prompt Engineering Patterns

As stages progress, you'll build prompts for different roles:

1. **Coach System Prompts** (Stage 2+)
   - Define personality and coaching philosophy
   - Set constraints (age-appropriate, safety-first)
   - Specify output format requirements

2. **Judge Prompts** (Stage 4+)
   - Provide evaluation criteria
   - Require structured output ("WINNER: A or WINNER: B")
   - Include fallback parsing strategies

3. **Debate Prompts** (Stage 5+)
   - Pass opponent context for rebuttals
   - Enforce brevity (100 words for cost management)
   - Maintain multi-turn conversation coherence

4. **Framework Integration** (Stage 6+)
   - Inject full Trojans framework into context
   - Require explicit framework element citations
   - Assess alignment with framework values

## Success Criteria

Project is considered successful when:
- Core AI orchestration patterns are understood and documented
- Functional debate system works end-to-end
- Learning objectives from REQUIREMENTS.md are met
- Insights are captured in LEARNING_LOG.md

**Note:** Stopping at Stage 4-5 is acceptable if core learning goals are achieved.
